{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["MIqF4cjDVOdZ","XdKgutqRVTAe","H9vzHA-MVYID","oVYqi5wZV-wX","_qCfPy3gWBze","SKadYxVaWJF9","I84ealAEhEqv","oMuOAcuN2d8b","-v6bgjvei8dp","8aS3seKgqrRc","477ZvfWDrbBo","akBxcRLCrfvk","xcawjISKvCAG","e6sj3RrbCWDH","ec6JKd5AvE3k","vG97YVmcDq9G","2iBacFb1EeTr"],"machine_shape":"hm","gpuType":"L4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# 檢查運算資源"],"metadata":{"id":"MIqF4cjDVOdZ"}},{"cell_type":"code","source":["import psutil\n","\n","# Check RAM\n","ram = psutil.virtual_memory()\n","print(f'Total RAM: {ram.total / (1024 ** 3):.2f} GB')\n","print(f'Available RAM: {ram.available / (1024 ** 3):.2f} GB')\n","\n","# Check Disk Space\n","disk = psutil.disk_usage('/')\n","print(f'Total Disk Space: {disk.total / (1024 ** 3):.2f} GB')\n","print(f'Used Disk Space: {disk.used / (1024 ** 3):.2f} GB')\n","print(f'Free Disk Space: {disk.free / (1024 ** 3):.2f} GB')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ooKo-VWEVScQ","outputId":"6c028487-42e1-4ddf-e8f3-f21cb0ac82c4","executionInfo":{"status":"ok","timestamp":1719330036182,"user_tz":-480,"elapsed":354,"user":{"displayName":"北科大-黃婉華","userId":"07380797156058868434"}}},"execution_count":445,"outputs":[{"output_type":"stream","name":"stdout","text":["Total RAM: 52.96 GB\n","Available RAM: 47.79 GB\n","Total Disk Space: 201.23 GB\n","Used Disk Space: 27.70 GB\n","Free Disk Space: 173.51 GB\n"]}]},{"cell_type":"code","source":["# from google.colab import drive\n","# drive.mount('/content/drive')"],"metadata":{"id":"8-N2JI8bFCSp","executionInfo":{"status":"ok","timestamp":1719330036777,"user_tz":-480,"elapsed":32,"user":{"displayName":"北科大-黃婉華","userId":"07380797156058868434"}}},"execution_count":446,"outputs":[]},{"cell_type":"markdown","source":["# 載入套件"],"metadata":{"id":"XdKgutqRVTAe"}},{"cell_type":"code","source":["# Importing necessary libraries\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","import torch.nn as nn\n","import torchvision.models as models\n","\n","from sklearn.ensemble import VotingClassifier, BaggingClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.neural_network import MLPClassifier\n","from xgboost import XGBClassifier\n","\n","from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n","from sklearn.utils.validation import has_fit_parameter\n","from sklearn.impute import SimpleImputer\n","from sklearn.base import BaseEstimator, ClassifierMixin\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import accuracy_score"],"metadata":{"id":"aNTS2YvBgSVI","executionInfo":{"status":"ok","timestamp":1719330036778,"user_tz":-480,"elapsed":32,"user":{"displayName":"北科大-黃婉華","userId":"07380797156058868434"}}},"execution_count":447,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"Lu3tXP1yE4YL"}},{"cell_type":"markdown","source":["# 上傳資料"],"metadata":{"id":"H9vzHA-MVYID"}},{"cell_type":"code","source":["# 讀取資料\n","def load_data(file_path):\n","    try:\n","      df = pd.read_csv('/content/sample_data/df_final_with_eco.csv', encoding='utf-8')\n","      return df\n","    except Exception as e:\n","      print(f\"Error loading data: {e}\")\n","      return None\n"],"metadata":{"id":"EEf-ehwQH0tr","executionInfo":{"status":"ok","timestamp":1719330036778,"user_tz":-480,"elapsed":32,"user":{"displayName":"北科大-黃婉華","userId":"07380797156058868434"}}},"execution_count":448,"outputs":[]},{"cell_type":"code","source":["# import pandas as pd\n","\n","# # 使用相對路徑載入資料\n","# df = pd.read_csv('/content/sample_data/df_final_with_eco.csv', encoding='utf-8')"],"metadata":{"id":"Cn2q0XkiVN6j","executionInfo":{"status":"ok","timestamp":1719330036778,"user_tz":-480,"elapsed":31,"user":{"displayName":"北科大-黃婉華","userId":"07380797156058868434"}}},"execution_count":449,"outputs":[]},{"cell_type":"code","source":["# df.head(2)"],"metadata":{"id":"CkzYMwPCU_9C","executionInfo":{"status":"ok","timestamp":1719330036779,"user_tz":-480,"elapsed":32,"user":{"displayName":"北科大-黃婉華","userId":"07380797156058868434"}}},"execution_count":450,"outputs":[]},{"cell_type":"markdown","source":["# 資料清整 (這裡給可靠的歐爸了)\n","\n","> 這邊主要是依據main()出現問題來添加的\n","\n","> def split_datasets(df):\n","\n","> 大致切割一下資料\n","\n","- 001-016 實價登入 estate\n","\n","- 017-052 經濟指標 eco\n","\n","- 053-156 比鄰   near"],"metadata":{"id":"oVYqi5wZV-wX"}},{"cell_type":"code","source":["# # 切割出經濟指標資料集 (017-052行)\n","# df_eco = df.iloc[16:52]\n","# # 切割出其餘資料集 (001-016行 實價登入 和 053-156行 比鄰)\n","# df_near_estate = pd.concat([df.iloc[:16], df.iloc[52:]], ignore_index=True)"],"metadata":{"id":"yuRx4Q9aMICm","executionInfo":{"status":"ok","timestamp":1719330036779,"user_tz":-480,"elapsed":32,"user":{"displayName":"北科大-黃婉華","userId":"07380797156058868434"}}},"execution_count":451,"outputs":[]},{"cell_type":"code","source":["# 切割資料集\n","def split_datasets(df):\n","    # 切割出經濟指標資料集 (017-052行)\n","    df_eco = df.iloc[16:52]\n","    # 切割出其餘資料集 (001-016行 實價登入 和 053-156行 比鄰)\n","    df_near_estate = pd.concat([df.iloc[:16], df.iloc[52:]], ignore_index=True)\n","    return df_eco, df_near_estate\n"],"metadata":{"id":"jJCZICvE6rFj","executionInfo":{"status":"ok","timestamp":1719330036779,"user_tz":-480,"elapsed":31,"user":{"displayName":"北科大-黃婉華","userId":"07380797156058868434"}}},"execution_count":452,"outputs":[]},{"cell_type":"code","source":["# 處理缺失值\n","def handle_missing_values(X):\n","    imputer = SimpleImputer(strategy='mean')\n","    X_imputed = imputer.fit_transform(X)\n","    return X_imputed"],"metadata":{"id":"YF8bHqnMRMBG","executionInfo":{"status":"ok","timestamp":1719330036779,"user_tz":-480,"elapsed":31,"user":{"displayName":"北科大-黃婉華","userId":"07380797156058868434"}}},"execution_count":453,"outputs":[]},{"cell_type":"markdown","source":["# 設定目標和特徵值\n","\n","> def prepare_data(df_near_estate):\n","\n","> df_near_estate"],"metadata":{"id":"_qCfPy3gWBze"}},{"cell_type":"code","source":["# # 設置 new_per_ping 為 y，其餘行數為 X\n","def prepare_data(df_near_estate):\n","    y = df_near_estate['new_per_ping']\n","    X = df_near_estate.drop(columns=['new_per_ping'])\n","    # 將連續變量轉換為分類變量\n","    y = pd.cut(y, bins=10, labels=False)  # 將數據分成 10 個區間\n","    # 確保標籤是連續的整數\n","    y, _ = pd.factorize(y)\n","    return X, y"],"metadata":{"id":"72VPOMk-57mb","executionInfo":{"status":"ok","timestamp":1719330036780,"user_tz":-480,"elapsed":31,"user":{"displayName":"北科大-黃婉華","userId":"07380797156058868434"}}},"execution_count":454,"outputs":[]},{"cell_type":"code","source":["# # 設置 new_per_ping 為 y，其餘行數為 X\n","# def prepare_data(df_near_estate):\n","#     y = df_near_estate['new_per_ping']\n","#     X = df_near_estate.drop(columns=['new_per_ping'])\n","#     # 將連續變量轉換為分類變量\n","#     y = pd.cut(y, bins=10, labels=False)  # 將數據分成 5 個區間\n","#     return X, y\n","\n","# # 如果 new_per_ping 是連續變量，這種分箱方法將會將其轉換為離散的分類標籤。"],"metadata":{"id":"-a1yDcyZyKz5","executionInfo":{"status":"ok","timestamp":1719330036780,"user_tz":-480,"elapsed":31,"user":{"displayName":"北科大-黃婉華","userId":"07380797156058868434"}}},"execution_count":455,"outputs":[]},{"cell_type":"code","source":["# y = df_near_estate['new_per_ping']\n","# X = df_near_estate.drop(columns=['new_per_ping'])"],"metadata":{"id":"uImqlyvSMh7P","executionInfo":{"status":"ok","timestamp":1719330036781,"user_tz":-480,"elapsed":31,"user":{"displayName":"北科大-黃婉華","userId":"07380797156058868434"}}},"execution_count":456,"outputs":[]},{"cell_type":"markdown","source":["# 切割資料為訓練、測試、(驗證)\n","\n","> 這個部分會在主程式中執行\n","\n","> df_near_estate 資料進行切割，使其分成 70% 的訓練集、15% 的測試集和 15% 的驗證集\n","\n","> df_near_estate\n","\n","> 設置 X_train, y_train 和 X_test, y_test\n","\n","> 驗證集的eco集5-6月資料我明天會抓"],"metadata":{"id":"SKadYxVaWJF9"}},{"cell_type":"code","source":["'''\n","# 取得資料的總筆數\n","n = len(df_near_estate)\n","\n","# 設定訓練集為總筆數的80%、測試集為總筆數的20%\n","n_train = int(0.8 * n)\n","n_test = n - n_train\n","\n","# 將資料前80%的資料作為訓練集\n","X_train = X[:n_train].values\n","y_train = y[:n_train].values\n","\n","# 將資料最後20%的資料作為測試集\n","X_test = X[-n_test:].values\n","y_test = y[-n_test:].values\n","\n","# 明天蒐集 5-6 月經濟指標作為驗證集\n","\n","'''"],"metadata":{"id":"Nr8ztVY8WYs7","colab":{"base_uri":"https://localhost:8080/","height":0},"outputId":"7b70cc89-79ba-4b66-f781-28b6ac7e8d57","executionInfo":{"status":"ok","timestamp":1719330036781,"user_tz":-480,"elapsed":31,"user":{"displayName":"北科大-黃婉華","userId":"07380797156058868434"}}},"execution_count":457,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n# 取得資料的總筆數\\nn = len(df_near_estate)\\n\\n# 設定訓練集為總筆數的80%、測試集為總筆數的20%\\nn_train = int(0.8 * n)\\nn_test = n - n_train\\n\\n# 將資料前80%的資料作為訓練集\\nX_train = X[:n_train].values\\ny_train = y[:n_train].values\\n\\n# 將資料最後20%的資料作為測試集\\nX_test = X[-n_test:].values\\ny_test = y[-n_test:].values\\n\\n# 明天蒐集 5-6 月經濟指標作為驗證集\\n\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":457}]},{"cell_type":"markdown","source":["# 模型建立 - Bagging Classifier 的打包\n","\n","- **使用 BaggingClassifier 對五種不同的分類器（決策樹、KNN、XGBoost、神經網絡和SVM）進行封裝。**\n","\n"," - create_bagging_classifiers 這個函數，創建包含多種袋裝分類器的字典。\n","\n"," - classifiers 是一個字典，包含不同的基本分類器。\n","\n"," - 返回一個字典，其中每個分類器都被袋裝技術包裝。\n","\n","\n","- **Bagging Classifier 的參數介紹**\n","  - base_estimator 是指定的基本分類器\n","\n","  - n_estimators 是袋裝中使用的基分類器的數量，\n","   - 設置 基分類器數量 為 10\n","\n","  - random_state 用於控制隨機數生成器，以保證結果的可重現性。\n","\n","   - 設置 隨機種子 為 42"],"metadata":{"id":"I84ealAEhEqv"}},{"cell_type":"code","source":["def create_bagging_classifiers():\n","    classifiers = {\n","        'KNN': SampleWeightWrapper(KNeighborsClassifier()),\n","        'XGBoost': SampleWeightWrapper(XGBClassifier()),\n","        'Neural Network': SampleWeightWrapper(MLPClassifier()),\n","        'SVM': SampleWeightWrapper(SVC(probability=True, max_iter=10000)),\n","        'Random Forest': SampleWeightWrapper(RandomForestClassifier())\n","        #'Custom NN': MyModel()  # 使用自定義的神經網絡模型\n","    }\n","\n","    bagging_classifiers = {}\n","    for name, clf in classifiers.items():\n","        bagging_classifiers[name] = BaggingClassifier(\n","            estimator=clf,\n","            n_estimators=10,\n","            random_state=42,\n","            bootstrap=True, # 使用bootstrap進行樣本選擇\n","            bootstrap_features=False # 不使用特徵bootstrap\n","        )\n","\n","    return bagging_classifiers, classifiers"],"metadata":{"id":"KFuu_7iTNDg2","executionInfo":{"status":"ok","timestamp":1719330036782,"user_tz":-480,"elapsed":29,"user":{"displayName":"北科大-黃婉華","userId":"07380797156058868434"}}},"execution_count":458,"outputs":[]},{"cell_type":"markdown","source":["## 自定義 - Custom NN\n","\n","> 在『自定義初始化基本分類器』當中使用的 function\n","\n","> the base classifiers\n","\n","> 基分類器 (中國)\n","\n","- 觀察權重調整前、後的\n"," - bias\n"," - weights"],"metadata":{"id":"oMuOAcuN2d8b"}},{"cell_type":"code","source":["class MyModel(BaseEstimator, ClassifierMixin):\n","    def __init__(self):\n","      super(MyModel, self).__init__()\n","      self.net = models.resnet18(weights=None)\n","      self.net.fc = nn.Linear(self.net.fc.in_features, 3)\n","      self.optimizer = torch.optim.Adam(self.net.parameters(), lr=0.001)\n","      self.criterion = nn.CrossEntropyLoss()\n","\n","    def fit(self, X, y, sample_weight=None):\n","      self.net.train()\n","      X_tensor = torch.tensor(X, dtype=torch.float32)\n","      y_tensor = torch.tensor(y, dtype=torch.long)\n","      if sample_weight is not None:\n","        ample_weight_tensor = torch.tensor(sample_weight, dtype=torch.float32)\n","      else:\n","        sample_weight_tensor = torch.ones_like(y_tensor, dtype=torch.float32)\n","\n","      for epoch in range(10):\n","        self.optimizer.zero_grad()\n","        outputs = self.net(X_tensor)\n","        loss = self.criterion(outputs, y_tensor)\n","        weighted_loss = loss * sample_weight_tensor\n","        weighted_loss.mean().backward()\n","        self.optimizer.step()\n","      return self\n","\n","    def predict(self, X):\n","      self.net.eval()\n","      X_tensor = torch.tensor(X, dtype=torch.float32)\n","      outputs = self.net(X_tensor)\n","      _, predicted = torch.max(outputs, 1)\n","      return predicted.numpy()\n"],"metadata":{"id":"LZzb6MWVBhFU","executionInfo":{"status":"ok","timestamp":1719330036782,"user_tz":-480,"elapsed":29,"user":{"displayName":"北科大-黃婉華","userId":"07380797156058868434"}}},"execution_count":459,"outputs":[]},{"cell_type":"code","source":["# # Define the custom neural network model\n","# class MyModel(nn.Module):\n","#     def __init__(self):\n","#         super(MyModel, self).__init__()\n","#         self.net = models.resnet18(pretrained=False)\n","#         self.net.fc = nn.Linear(self.net.fc.in_features, 3)  # 修改輸出層大小以匹配Iris數據集\n","\n","#         # 打印初始化權重和偏差\n","#         print('Initial weights: ', self.net.fc.weight[0][:10])\n","#         print('Initial bias: ', self.net.fc.bias[:10])\n","\n","#         # 計算初始化權重和偏差的變異數\n","#         initial_weights_variance = self.calculate_variance(self.net.fc.weight)\n","#         initial_bias_variance = self.calculate_variance(self.net.fc.bias)\n","#         print('Initial weights variance:', initial_weights_variance)\n","#         print('Initial bias variance:', initial_bias_variance)\n","#         print('=====================')\n","\n","#         # 自定義權重和偏差\n","#         self.net.fc.weight = torch.nn.Parameter(torch.ones(self.net.fc.weight.shape) * 0.9, requires_grad=True)\n","#         self.net.fc.bias = torch.nn.Parameter(torch.zeros(self.net.fc.bias.shape), requires_grad=True)\n","\n","#         # 打印自定義後的權重和偏差\n","#         print('Custom weights: ', self.net.fc.weight[0][:10])\n","#         print('Custom bias: ', self.net.fc.bias[:10])\n","\n","#         # 計算自定義後權重和偏差的變異數\n","#         custom_weights_variance = self.calculate_variance(self.net.fc.weight)\n","#         custom_bias_variance = self.calculate_variance(self.net.fc.bias)\n","#         print('Custom weights variance:', custom_weights_variance)\n","#         print('Custom bias variance:', custom_bias_variance)\n","\n","#     def forward(self, x):\n","#         output = self.net(x)\n","#         return output\n","\n","#     def calculate_variance(self, tensor):\n","#         return torch.var(tensor).item()"],"metadata":{"id":"AHqbTmi22eML","executionInfo":{"status":"ok","timestamp":1719330036782,"user_tz":-480,"elapsed":28,"user":{"displayName":"北科大-黃婉華","userId":"07380797156058868434"}}},"execution_count":460,"outputs":[]},{"cell_type":"markdown","source":["# 自定義 - 分類器包裝器\n","\n","> 這個類用於包裝不支持 sample_weight 參數的分類器，以便能夠忽略 sample_weight 參數。。"],"metadata":{"id":"8Hg-uQeg2Unh"}},{"cell_type":"code","source":["# 自定義 - 分類器包裝器\n","class SampleWeightWrapper(BaseEstimator, ClassifierMixin):\n","    def __init__(self, estimator):\n","        self.estimator = estimator\n","\n","    # 修改的部分：確保忽略不接受 sample_weight 的分類器\n","    def fit(self, X, y, sample_weight=None):\n","        if sample_weight is not None:\n","            try:\n","                self.estimator.fit(X, y, sample_weight=sample_weight)\n","            except TypeError:\n","                self.estimator.fit(X, y)\n","        else:\n","            self.estimator.fit(X, y)\n","        return self\n","\n","    def predict(self, X):\n","        return self.estimator.predict(X)\n","\n","    def predict_proba(self, X):\n","        if hasattr(self.estimator, \"predict_proba\"):\n","            return self.estimator.predict_proba(X)\n","        else:\n","            raise AttributeError(f\"{self.estimator.__class__.__name__} does not support predict_proba method\")\n","\n","    def __getattr__(self, attr):\n","        return getattr(self.estimator, attr)"],"metadata":{"id":"FGNxOe_mQaV5","executionInfo":{"status":"ok","timestamp":1719330036783,"user_tz":-480,"elapsed":29,"user":{"displayName":"北科大-黃婉華","userId":"07380797156058868434"}}},"execution_count":461,"outputs":[]},{"cell_type":"markdown","source":["# 訓練 Bagging Classifiers & 增加樣本權重\n","\n","- train_bagging_classifiers 這個函數，訓練每個袋裝分類器。\n","\n"," - bagging_classifiers 是 create_bagging_classifiers 返回的袋裝分類器字典。\n","\n"," - X_train 和 y_train 是 訓練數據 (train data)。\n","\n"," - 返回訓練好的袋裝分類器字典。"],"metadata":{"id":"-v6bgjvei8dp"}},{"cell_type":"code","source":["def train_bagging_classifiers(bagging_classifiers, X_train, y_train):\n","    for name, classifier in bagging_classifiers.items():\n","        print(f\"Training {name}\")\n","        classifier.fit(X_train, y_train)\n","    return bagging_classifiers"],"metadata":{"id":"R3hQoS7za-o7","executionInfo":{"status":"ok","timestamp":1719330036783,"user_tz":-480,"elapsed":28,"user":{"displayName":"北科大-黃婉華","userId":"07380797156058868434"}}},"execution_count":462,"outputs":[]},{"cell_type":"code","source":["# # Train the BaggingClassifiers\n","# bagging_decision_tree.fit(X_train, y_train)\n","# bagging_knn.fit(X_train, y_train)\n","# bagging_xgboost.fit(X_train, y_train)\n","# bagging_nn.fit(X_train, y_train)\n","# bagging_svm.fit(X_train, y_train)"],"metadata":{"id":"ubXL1y5Yp2_l","executionInfo":{"status":"ok","timestamp":1719330036784,"user_tz":-480,"elapsed":29,"user":{"displayName":"北科大-黃婉華","userId":"07380797156058868434"}}},"execution_count":463,"outputs":[]},{"cell_type":"markdown","source":["# 用訓練好的 bagging classifiers 預測\n","\n","- make_predictions 這個函數，使用訓練好的袋裝分類器 (bagging classifiers) 對測試集 (test data) 進行預測。\n","\n"," - bagging_classifiers 是訓練好的袋裝分類器字典。\n","\n"," - X_test 是測試數據。\n","\n"," - 返回包含每個分類器預測結果的字典。"],"metadata":{"id":"8aS3seKgqrRc"}},{"cell_type":"code","source":["# make_predictions 函數\n","def make_predictions(bagging_classifiers, X_test, y_test):\n","    predictions = {}\n","    for name, classifier in bagging_classifiers.items():\n","        # 確保所有分類器具有相同的類別數量\n","        if hasattr(classifier, \"n_classes_\") and classifier.n_classes_ != len(np.unique(y_test)):\n","            continue\n","        # 進行預測並保存結果\n","        predictions[name] = classifier.predict(X_test)\n","    return predictions"],"metadata":{"id":"AcxLcULBrRxh","executionInfo":{"status":"ok","timestamp":1719330036785,"user_tz":-480,"elapsed":29,"user":{"displayName":"北科大-黃婉華","userId":"07380797156058868434"}}},"execution_count":464,"outputs":[]},{"cell_type":"code","source":["# # Make predictions on the test set\n","# # predict 方法將測試數據（X_test）傳遞給每個袋裝分類器，並返回預測標籤。\n","# y_pred_dt = bagging_decision_tree.predict(X_test)\n","# y_pred_knn = bagging_knn.predict(X_test)\n","# y_pred_xgb = bagging_xgboost.predict(X_test)\n","# y_pred_nn = bagging_nn.predict(X_test)\n","# y_pred_svm = bagging_svm.predict(X_test)"],"metadata":{"id":"IHo0EB_eqvZ-","executionInfo":{"status":"ok","timestamp":1719330036785,"user_tz":-480,"elapsed":29,"user":{"displayName":"北科大-黃婉華","userId":"07380797156058868434"}}},"execution_count":465,"outputs":[]},{"cell_type":"markdown","source":["# 計算每個袋裝分類器 (bagging classifiers) 的準確率\n","\n","- calculate_accuracies 這個函數，對測試集 (test data) 的真實標籤（y_test）和預測標籤（y_pred）進行比較，並且計算每個袋裝分類器的準確率 (accuracy)。\n","\n"," - predictions 是包含每個分類器預測結果的字典。\n","\n"," - y_test 是測試數據的真實標籤。\n","\n"," - 返回包含每個分類器準確率的字典。\n","\n"],"metadata":{"id":"477ZvfWDrbBo"}},{"cell_type":"code","source":["# 計算每個袋裝分類器的準確率\n","def calculate_accuracies(predictions, y_test):\n","    accuracies = {}\n","    for name, y_pred in predictions.items():\n","        # 計算準確率並保存結果\n","        accuracies[name] = accuracy_score(y_test, y_pred)\n","    return accuracies"],"metadata":{"id":"od0hqQPRsBpI","executionInfo":{"status":"ok","timestamp":1719330036785,"user_tz":-480,"elapsed":29,"user":{"displayName":"北科大-黃婉華","userId":"07380797156058868434"}}},"execution_count":466,"outputs":[]},{"cell_type":"markdown","source":["# 輸出每個袋裝分類器 (bagging classifiers) 的準確率\n","\n","- print_accuracies 這個函數，輸出每個袋裝分類器的準確率。\n","\n"," - accuracies 是包含每個分類器準確率的字典。"],"metadata":{"id":"akBxcRLCrfvk"}},{"cell_type":"code","source":["# 打印每個袋裝分類器的準確率\n","def print_accuracies(accuracies):\n","    for name, accuracy in accuracies.items():\n","        print(f\"{name} Bagging Accuracy: {accuracy}\")"],"metadata":{"id":"c3qvMIUquSfl","executionInfo":{"status":"ok","timestamp":1719330036786,"user_tz":-480,"elapsed":29,"user":{"displayName":"北科大-黃婉華","userId":"07380797156058868434"}}},"execution_count":467,"outputs":[]},{"cell_type":"markdown","source":["# 使用例子\n","\n","> (練習用的，可以省略)"],"metadata":{"id":"xcawjISKvCAG"}},{"cell_type":"code","source":["'''\n","# 使用例子\n","classifiers = {\n","    'Decision Tree': DecisionTreeClassifier(),\n","    'KNN': KNeighborsClassifier(),\n","    'XGBoost': XGBClassifier(),\n","    'Neural Network': MLPClassifier(),\n","    'SVM': SVC()\n","}\n","\n","# 假設 X_train, y_train, X_test, y_test 已經定義\n","# 你需要根據你的資料來定義這些變數\n","# X_train, y_train, X_test, y_test = ...\n","\n","# 對少數類別樣本給予更高的權重\n","sample_weight = np.ones(len(y_train))\n","sample_weight[y_train == 1] *= 10\n","\n","# 創建並訓練袋裝分類器\n","bagging_classifiers = create_bagging_classifiers(classifiers)\n","trained_classifiers = train_bagging_classifiers(bagging_classifiers, X_train, y_train, sample_weight)\n","# 使用訓練好的袋裝分類器進行預測\n","predictions = make_predictions(trained_classifiers, X_test)\n","# 計算準確率\n","accuracies = calculate_accuracies(predictions, y_test)\n","# 打印準確率\n","print_accuracies(accuracies)\n","\n","'''"],"metadata":{"id":"0ITsZEcPvH4O","colab":{"base_uri":"https://localhost:8080/","height":0},"outputId":"16050256-ee3e-4cc8-fb8f-e63a3d9002d3","executionInfo":{"status":"ok","timestamp":1719330036787,"user_tz":-480,"elapsed":30,"user":{"displayName":"北科大-黃婉華","userId":"07380797156058868434"}}},"execution_count":468,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\n# 使用例子\\nclassifiers = {\\n    'Decision Tree': DecisionTreeClassifier(),\\n    'KNN': KNeighborsClassifier(),\\n    'XGBoost': XGBClassifier(),\\n    'Neural Network': MLPClassifier(),\\n    'SVM': SVC()\\n}\\n\\n# 假設 X_train, y_train, X_test, y_test 已經定義\\n# 你需要根據你的資料來定義這些變數\\n# X_train, y_train, X_test, y_test = ...\\n\\n# 對少數類別樣本給予更高的權重\\nsample_weight = np.ones(len(y_train))\\nsample_weight[y_train == 1] *= 10\\n\\n# 創建並訓練袋裝分類器\\nbagging_classifiers = create_bagging_classifiers(classifiers)\\ntrained_classifiers = train_bagging_classifiers(bagging_classifiers, X_train, y_train, sample_weight)\\n# 使用訓練好的袋裝分類器進行預測\\npredictions = make_predictions(trained_classifiers, X_test)\\n# 計算準確率\\naccuracies = calculate_accuracies(predictions, y_test)\\n# 打印準確率\\nprint_accuracies(accuracies)\\n\\n\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":468}]},{"cell_type":"markdown","source":["# 投票分類器 (voting_classifier) 和 袋裝分類器 (bagging_classifier) 的差異 (純敘述)"],"metadata":{"id":"e6sj3RrbCWDH"}},{"cell_type":"markdown","source":["> **這兩個函數的主要區別在於它們所創建的分類器的種類及其運作方式：**\n","\n","> **create_voting_classifier 函數：**\n","\n","- 目的：創建一個投票分類器（Voting Classifier）。\n","\n","- 機制：投票分類器會整合多個基分類器的預測結果，並通過投票（可以是硬投票或軟投票）來決定最終的預測結果。硬投票是根據每個基分類器的預測類別進行投票，而軟投票則是根據每個基分類器的預測概率進行投票。\n","\n","- 組成：該函數使用 VotingClassifier 來組合五個基分類器（Decision Tree、KNN、XGBoost、NN 和 SVC），並使用軟投票機制來進行預測。\n","\n","\n","> **create_bagging_classifier 函數：**\n","\n","- 目的：創建一個袋裝分類器（Bagging Classifier），其基分類器為投票分類器。\n","\n","- 機制：袋裝分類器是一種集成方法，通過在訓練數據的不同子集上訓練多個基分類器來提高模型的穩定性和準確性。這些基分類器的預測結果將進行平均或投票以生成最終預測。袋裝分類器通常使用的是相同類型的基分類器，但這裡是用投票分類器作為基分類器。\n","\n","- 組成：該函數使用 BaggingClassifier，將投票分類器作為其基分類器（base_estimator），並創建 50 個這樣的投票分類器來進行袋裝。\n","\n","> **簡單總結：**\n","\n","- create_voting_classifier：創建一個單一的投票分類器，整合多個基分類器的預測結果，通過投票來決定最終的預測結果。\n","\n","- create_bagging_classifier：創建一個袋裝分類器，使用多個投票分類器作為基分類器，通過在不同子集上訓練這些基分類器來提高模型的穩定性和準確性，最終的預測結果是這些投票分類器的平均或投票結果。\n","\n","> **這兩個函數所創建的分類器的運作方式如下圖所示：**\n","\n","- 投票分類器（Voting Classifier）：\n","\n"," - 基分類器 1 → 預測\n"," - 基分類器 2 → 預測\n"," - 基分類器 3 → 預測\n"," - 基分類器 4 → 預測\n"," - 基分類器 5 → 預測\n"," - 投票（硬/軟） → 最終預測\n","\n","- 袋裝分類器（Bagging Classifier）：\n","\n"," - 投票分類器 1（包含多個基分類器） → 預測\n"," - 投票分類器 2（包含多個基分類器） → 預測\n"," - 投票分類器 3（包含多個基分類器） → 預測\n"," - ...\n"," - 投票分類器 50（包含多個基分類器） → 預測\n"," - 平均/投票 → 最終預測"],"metadata":{"id":"dHi-fUaICd4H"}},{"cell_type":"markdown","source":["# 創建投票分類器 (voting classifier) 的函數"],"metadata":{"id":"ec6JKd5AvE3k"}},{"cell_type":"code","source":["def create_voting_classifier(base_clfs, X_train):\n","    print(\"Available classifiers in base_clfs:\", base_clfs.keys())\n","    # 檢查所有基分類器是否支持 predict_proba 方法\n","    valid_estimators = []\n","    for name, clf in base_clfs.items():\n","        if hasattr(clf, \"predict_proba\"):\n","            # 檢查分類器的 predict_proba 方法返回的輸出形狀\n","            try:\n","                test_proba = clf.predict_proba(X_train[:10])\n","                print(f\"{name} predict_proba shape: {test_proba.shape}\")\n","                valid_estimators.append((name, clf))\n","            except Exception as e:\n","                print(f\"{name} failed predict_proba check: {e}\")\n","\n","    if len(valid_estimators) == 0:\n","        raise ValueError(\"None of the classifiers support predict_proba method.\")\n","\n","    # 創建一個軟投票分類器\n","    voting_clf = VotingClassifier(estimators=valid_estimators, voting='soft')\n","    return voting_clf"],"metadata":{"id":"QWH1bra9-OiD","executionInfo":{"status":"ok","timestamp":1719330036787,"user_tz":-480,"elapsed":28,"user":{"displayName":"北科大-黃婉華","userId":"07380797156058868434"}}},"execution_count":469,"outputs":[]},{"cell_type":"markdown","source":["# 創建袋裝投票分類器 (bagging classifier) 的函數"],"metadata":{"id":"vG97YVmcDq9G"}},{"cell_type":"code","source":["# 創建袋裝投票分類器的函數\n","def create_bagging_classifier(voting_clf):\n","    # 使用投票分類器作為基分類器創建袋裝分類器\n","    bagging_clf = BaggingClassifier(estimator=voting_clf, n_estimators=50, random_state=42)\n","    return bagging_clf"],"metadata":{"id":"nc2P1BqiDy-T","executionInfo":{"status":"ok","timestamp":1719330036787,"user_tz":-480,"elapsed":28,"user":{"displayName":"北科大-黃婉華","userId":"07380797156058868434"}}},"execution_count":470,"outputs":[]},{"cell_type":"markdown","source":["# 驗證袋裝投票分類器的函數\n","\n","> 這裡會用到 驗證集\n","\n","> 訓練並評估袋裝投票分類器的函數，增加樣本權重"],"metadata":{"id":"2iBacFb1EeTr"}},{"cell_type":"code","source":["def train_and_evaluate_bagging_clf(bagging_clf, X_train, y_train, X_val, y_val, X_test, y_test):\n","    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n","    val_accuracies = []\n","\n","    for train_index, val_index in skf.split(X_train, y_train):\n","        X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n","        y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n","\n","        if has_fit_parameter(bagging_clf, \"sample_weight\"):\n","            bagging_clf.fit(X_train_fold, y_train_fold, sample_weight=np.ones(len(y_train_fold)))\n","        else:\n","            bagging_clf.fit(X_train_fold, y_train_fold)\n","\n","        # 確保 VotingClassifier 中的所有估計器具有相同的類別，並處理潛在的形狀不匹配問題\n","        unique_classes = np.unique(y_train)\n","        for clf in bagging_clf.estimators_:\n","            if hasattr(clf, \"classes_\"):\n","                clf.classes_ = unique_classes\n","            # 檢查估計器是否具有 'predict_proba' 方法，並處理潛在的形狀問題\n","            if hasattr(clf, \"predict_proba\"):\n","                try:\n","                    # 嘗試在小樣本上進行預測以檢查形狀錯誤\n","                    proba = clf.predict_proba(X_val_fold[:1])\n","                    if proba.shape[1] != len(unique_classes): # 檢查預測的類別數量是否匹配\n","                        print(f\"估計器 {clf.__class__.__name__} 預測的類別數量不同。正在重新訓練完整的資料...\")\n","                        clf.fit(X_train, y_train) # 在完整的訓練資料上重新訓練以確保一致性\n","                except ValueError as e:\n","                    print(f\"估計器 {clf.__class__.__name__} 引發 ValueError: {e}。正在重新訓練完整的資料...\")\n","                    clf.fit(X_train, y_train) # 在完整的訓練資料上重新訓練以潛在地解決問題\n","\n","        val_predictions = bagging_clf.predict(X_val_fold)\n","        val_accuracy = accuracy_score(y_val_fold, val_predictions)\n","        val_accuracies.append(val_accuracy)\n","\n","    val_accuracy = np.mean(val_accuracies)\n","\n","    # 在對測試資料進行預測之前，確保 VotingClassifier 中的所有估計器具有相同的類別\n","    for clf in bagging_clf.estimators_:\n","        if hasattr(clf, \"classes_\"):\n","            clf.classes_ = unique_classes\n","\n","    test_predictions = bagging_clf.predict(X_test)\n","    test_accuracy = accuracy_score(y_test, test_predictions)\n","\n","    return val_accuracy, test_accuracy"],"metadata":{"id":"cfH4jFCvGZFb","executionInfo":{"status":"aborted","timestamp":1719331657534,"user_tz":-480,"elapsed":11,"user":{"displayName":"北科大-黃婉華","userId":"07380797156058868434"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # ChatGPT-4o\n","# # 訓練並評估袋裝投票分類器\n","# def train_and_evaluate_bagging_clf(bagging_clf, X_train, y_train, X_val, y_val, X_test, y_test):\n","#     skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n","#     val_accuracies = []\n","\n","#     for train_index, val_index in skf.split(X_train, y_train):\n","#         X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n","#         y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n","\n","#         if has_fit_parameter(bagging_clf, \"sample_weight\"):\n","#             bagging_clf.fit(X_train_fold, y_train_fold, sample_weight=np.ones(len(y_train_fold)))\n","#         else:\n","#             bagging_clf.fit(X_train_fold, y_train_fold)\n","\n","#         unique_classes = np.unique(y_train)\n","#         for clf in bagging_clf.estimators_:\n","#             if hasattr(clf, \"classes_\"):\n","#                 clf.classes_ = unique_classes\n","\n","#         val_predictions = bagging_clf.predict(X_val_fold)\n","#         val_accuracy = accuracy_score(y_val_fold, val_predictions)\n","#         val_accuracies.append(val_accuracy)\n","\n","#     val_accuracy = np.mean(val_accuracies)\n","#     test_predictions = bagging_clf.predict(X_test)\n","#     test_accuracy = accuracy_score(y_test, test_predictions)\n","\n","#     return val_accuracy, test_accuracy"],"metadata":{"id":"RyF038RuChAl","executionInfo":{"status":"ok","timestamp":1719330036788,"user_tz":-480,"elapsed":28,"user":{"displayName":"北科大-黃婉華","userId":"07380797156058868434"}}},"execution_count":471,"outputs":[]},{"cell_type":"markdown","source":["# main function\n","\n","> - 整理執行時出現的問題\n","\n","> 1. 這裡我先假設了 y 是類別型\n","\n","> 2. 發現 X 有 NaN值，所以增加了處理方式<br></br>\n"," → 加上一個 function : handle_missing_values\n","\n","> 3. 即使在代碼中沒有明確傳遞樣本權重，BaggingClassifier 仍會嘗試傳遞樣本權重給基分類器。對於不支持樣本權重的分類器，如 KNeighborsClassifier，這會引發錯誤。<br></br>\n"," → TypeError: Underlying estimator KNeighborsClassifier does not support sample weights.<br></br>\n"," → 修改 BaggingClassifier 的參數\n","\n","> 4. X_train 和 y_train 是 numpy 數組，而不是 pandas 的 DataFrame 或 Series。<br></br>\n"," → 轉換成 pandas 的數據結構，或者直接使用 numpy 的索引，避免 AttributeError。<br></br>\n"," → 這裡是使用 numpy 索引的版本。\n","\n","> 5. 在 train_and_evaluate_bagging_clf 函數中，將 y_train 轉換為 numpy 數組，避免 KeyError。<br></br>\n"," → 將 y_train 轉換為 numpy 數組\n","\n","> 6. BaggingClassifier 在訓練之前不會創建 estimators_ 屬性，因此在 fit 方法調用之前不能訪問該屬性\n","\n","> 7. 你的 VotingClassifier 中的一個或多個估計器的 predict_proba 方法傳回結果的形狀不一致，這可能是因為不同的估計器預測了不同數量的類別。錯誤訊息指出在 2 維之後形狀不一致，進一步支持了這一點\n"," → 處理之後還是有這個問題，表示你的個別估計器的訓練或配置方式存在更深層的問題。"],"metadata":{"id":"j8CmX5-67BBm"}},{"cell_type":"code","source":["def main():\n","    # 讀取資料\n","    df = load_data('/content/sample_data/df_final_with_eco.csv')\n","    if df is None:\n","        return\n","\n","    # 切割資料集\n","    df_eco, df_near_estate = split_datasets(df)\n","\n","    # 設置資料和標籤\n","    X, y = prepare_data(df_near_estate)\n","\n","    # 處理缺失值\n","    X = handle_missing_values(X)\n","\n","    # # 確定訓練集和測試集的大小\n","    # n = len(df_near_estate)\n","    # n_train = int(0.8 * n)\n","    # n_test = n - n_train\n","    # # 切割訓練集和測試集\n","    # X_train = X[:n_train]\n","    # y_train = y[:n_train]\n","    # X_test = X[-n_test:]\n","    # y_test = y[-n_test:]\n","\n","    # 切割資料集成訓練集、測試集和驗證集\n","    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)  # 70% 訓練集，30% 暫存集\n","    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)  # 15% 測試集，15% 驗證集\n","\n","    # 創建袋裝分類器\n","    bagging_classifiers, classifiers = create_bagging_classifiers()\n","\n","    # 訓練袋裝分類器\n","    bagging_classifiers = train_bagging_classifiers(bagging_classifiers, X_train, y_train)\n","\n","    # 計算袋裝分類器的預測結果\n","    bagging_predictions = make_predictions(bagging_classifiers, X_test, y_test)\n","\n","    # 計算袋裝分類器的準確率\n","    bagging_accuracies = calculate_accuracies(bagging_predictions, y_test)\n","\n","    # 打印袋裝分類器的準確率\n","    for name, accuracy in bagging_accuracies.items():\n","        print(f\"{name} Bagging Accuracy: {accuracy}\")\n","\n","    # 訓練基分類器\n","    for name, clf in classifiers.items():\n","        clf.fit(X_train, y_train)\n","\n","    # 創建投票分類器\n","    voting_clf = create_voting_classifier(classifiers, X_train)\n","\n","    # 創建袋裝投票分類器\n","    bagging_clf = create_bagging_classifier(voting_clf)\n","\n","    # 訓練並評估袋裝投票分類器\n","    # ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 758) + inhomogeneous part.\n","    # 可能表示你的個別估計器的訓練或配置方式存在更深層的問題。\n","    val_accuracy, test_accuracy = train_and_evaluate_bagging_clf(bagging_clf, X_train, y_train, X_val, y_val, X_test, y_test)\n","\n","    # 打印準確率\n","    print(\"Validation Accuracy: \", val_accuracy)\n","    print(\"Test Accuracy: \", test_accuracy)\n","\n","# 執行主函數\n","main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"lnkiCB79_wYg","executionInfo":{"status":"error","timestamp":1719331657532,"user_tz":-480,"elapsed":859420,"user":{"displayName":"北科大-黃婉華","userId":"07380797156058868434"}},"outputId":"25839784-a3dc-4c0f-e1b0-fe76c6b1bbda"},"execution_count":479,"outputs":[{"output_type":"stream","name":"stdout","text":["Training KNN\n","Training XGBoost\n","Training Neural Network\n","Training SVM\n","Training Random Forest\n","Available classifiers in base_clfs: dict_keys(['KNN', 'XGBoost', 'Neural Network', 'SVM', 'Random Forest'])\n","KNN predict_proba shape: (10, 9)\n","XGBoost predict_proba shape: (10, 9)\n","Neural Network predict_proba shape: (10, 9)\n","SVM predict_proba shape: (10, 9)\n","Random Forest predict_proba shape: (10, 9)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier predicts different number of classes. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier predicts different number of classes. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier predicts different number of classes. Retraining on full data...\n","Estimator VotingClassifier predicts different number of classes. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier predicts different number of classes. Retraining on full data...\n","Estimator VotingClassifier predicts different number of classes. Retraining on full data...\n","Estimator VotingClassifier predicts different number of classes. Retraining on full data...\n","Estimator VotingClassifier predicts different number of classes. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier predicts different number of classes. Retraining on full data...\n","Estimator VotingClassifier predicts different number of classes. Retraining on full data...\n","Estimator VotingClassifier predicts different number of classes. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier predicts different number of classes. Retraining on full data...\n","Estimator VotingClassifier predicts different number of classes. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier predicts different number of classes. Retraining on full data...\n","Estimator VotingClassifier predicts different number of classes. Retraining on full data...\n","Estimator VotingClassifier predicts different number of classes. Retraining on full data...\n","Estimator VotingClassifier predicts different number of classes. Retraining on full data...\n","Estimator VotingClassifier predicts different number of classes. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier predicts different number of classes. Retraining on full data...\n","Estimator VotingClassifier predicts different number of classes. Retraining on full data...\n","Estimator VotingClassifier predicts different number of classes. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier predicts different number of classes. Retraining on full data...\n","Estimator VotingClassifier predicts different number of classes. Retraining on full data...\n","Estimator VotingClassifier predicts different number of classes. Retraining on full data...\n","Estimator VotingClassifier predicts different number of classes. Retraining on full data...\n","Estimator VotingClassifier predicts different number of classes. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier predicts different number of classes. Retraining on full data...\n","Estimator VotingClassifier predicts different number of classes. Retraining on full data...\n","Estimator VotingClassifier predicts different number of classes. Retraining on full data...\n","Estimator VotingClassifier predicts different number of classes. Retraining on full data...\n","Estimator VotingClassifier predicts different number of classes. Retraining on full data...\n","Estimator VotingClassifier predicts different number of classes. Retraining on full data...\n","Estimator VotingClassifier predicts different number of classes. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier predicts different number of classes. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier predicts different number of classes. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier raised ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 1) + inhomogeneous part.. Retraining on full data...\n","Estimator VotingClassifier predicts different number of classes. Retraining on full data...\n"]},{"output_type":"error","ename":"IndexError","evalue":"index 8 is out of bounds for axis 1 with size 8","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-479-faa84e8ed17d>\u001b[0m in \u001b[0;36m<cell line: 66>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;31m# 執行主函數\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-479-faa84e8ed17d>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 758) + inhomogeneous part.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# 可能表示你的個別估計器的訓練或配置方式存在更深層的問題。\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mval_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_and_evaluate_bagging_clf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbagging_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;31m# 打印準確率\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-478-c20c2b1bc1dd>\u001b[0m in \u001b[0;36mtrain_and_evaluate_bagging_clf\u001b[0;34m(bagging_clf, X_train, y_train, X_val, y_val, X_test, y_test)\u001b[0m\n\u001b[1;32m     29\u001b[0m                     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Retrain on full training data to potentially resolve issues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mval_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbagging_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mval_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mval_accuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    825\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m         \"\"\"\n\u001b[0;32m--> 827\u001b[0;31m         \u001b[0mpredicted_probabilitiy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    828\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_probabilitiy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    863\u001b[0m         \u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_partition_estimators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 865\u001b[0;31m         all_proba = Parallel(\n\u001b[0m\u001b[1;32m    866\u001b[0m             \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parallel_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m         \u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py\u001b[0m in \u001b[0;36m_parallel_predict_proba\u001b[0;34m(estimators, estimators_features, X, n_classes)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m                 proba[:, estimator.classes_] += proba_estimator[\n\u001b[0m\u001b[1;32m    166\u001b[0m                     \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                 ]\n","\u001b[0;31mIndexError\u001b[0m: index 8 is out of bounds for axis 1 with size 8"]}]}]}